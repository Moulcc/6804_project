{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb672cde-d0bb-4e32-aa06-39ef84fbabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9be14-3e98-4bac-a03a-e45a3f1b08ce",
   "metadata": {},
   "source": [
    "## 1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52637543-aaaa-4dff-99b2-02ab0225143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac7a8c-20a9-46f8-bbec-e151a6b5b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5681a6d-951d-4729-ba22-7a07ff9ba2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de505c65-a5f7-4f0f-b5e2-1fd943cfd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d473c93-9b4f-4270-be5d-7a60c3271c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fraud proportion takes up {}%'.format(round(df['Class'].value_counts().values[1]/len(df['Class']) * 100, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ebc9b7-9b27-4f15-9cfa-86d244d30c51",
   "metadata": {},
   "source": [
    "## 2 Data Processing \n",
    "### 2.1 Data Splitting and Standardizatioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f19c9f-d4ef-433a-9093-f367112a4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1)\n",
    "y = df.Class\n",
    "no_stand_X_features = X.columns\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52da2d-f57a-4842-a3b0-44138993bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867353f-94b7-4bb4-b1fe-55d3554659ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(df, name):\n",
    "    new_name = name+'_stand'\n",
    "    df[new_name]= (df[name] - df[name].mean()) / df[name].std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Standardize the X_train dataset\n",
    "features_lst = X.columns\n",
    "for i in features_lst:\n",
    "    standardization(X_train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e403b-bd62-4bab-872f-eeff148f775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_test(x_train, x_test, name):\n",
    "    new_name = name+'_stand'\n",
    "    x_test[new_name]= (x_test[name] - x_train[name].mean()) / x_train[name].std()\n",
    "    \n",
    "    return x_test\n",
    "\n",
    "# Standardize the X_test dataset\n",
    "for j in features_lst:\n",
    "    standardize_test(X_train, X_test, j)\n",
    "\n",
    "stand_X_features = [i+'_stand' for i in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24eeef-9604-4a99-8bba-b0f43f1e022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c47a8a-b31b-4031-b6ff-08f08d60c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51e6ee-db60-4b98-9af1-e84393130868",
   "metadata": {},
   "source": [
    "### 2.1 Handeling Imbalanced Dataset Methods\n",
    "**SMOTE**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eadd0b-dbf6-4ec6-9f66-40114be8262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SMOTE\n",
    "# sm = SMOTE(random_state = 0)\n",
    "# X_sampled_smote, y_sampled_smote = sm.fit_resample(X_train, y_train)\n",
    "# # X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_sampled_smote, y_sampled_smote, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# print(\"Before performing smote : \", Counter(y_train))\n",
    "# print(\"After performing smote : \", Counter(y_sampled_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496eaefb-e43b-41ff-bec3-bfbab138e155",
   "metadata": {},
   "source": [
    "## Supervised Learning \n",
    "**Logistic Regression** - ysy <br>\n",
    "**K-Nearest Neighbors** - mql <br>\n",
    "**Decision Tree** <br>\n",
    "**Random Forest** - isha <br>\n",
    "**Support Vector Machine Classifier (SVC)** <br>\n",
    "**AdaBoost** <br>\n",
    "**Gradient Boosting Classifier** - zzy <br>\n",
    "\n",
    "Later, EDA and feature engineering are needed to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a95b09-f6f9-4b16-a20b-35075dc3facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(test_y, pred_y):\n",
    "    print(\"Classification accuracy is: \\n\", metrics.confusion_matrix(test_y, pred_y, normalize='all'))\n",
    "    cf_matrix = metrics.confusion_matrix(test_y, pred_y)\n",
    "    print(\"Confusion Matrix is: \\n\", cf_matrix)\n",
    "    print(\"Classification report is: \\n\", classification_report(test_y, pred_y))\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    \n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    \n",
    "    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=labels, fmt='', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix with Normalization\")\n",
    "    plt.xlabel(\"Predicated Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9907c-4bde-4440-ab45-644b2dbfbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, model_classifier, model_name):\n",
    "    print(model_name+' without using smote')\n",
    "    model = model_classifier\n",
    "    model.fit(X_train[features], y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test[features])\n",
    "    y_pred_proba = model.predict_proba(X_test[features])[:, 1] # Keep probabilities for the positive outcome only\n",
    "    \n",
    "    confusion_matrix(y_test, y_pred)\n",
    "    # Accuracy\n",
    "    print(\"Accuracy (R^2) of Train Dataset: \", model.score(X_train[features], y_train))\n",
    "    print(\"Accuracy (R^2) of Test Dataset: \", model.score(X_test[features], y_test))\n",
    "    print('Accuracy score overall: ', metrics.accuracy_score(y_test, y_pred))\n",
    "    print('Recall score is {}%'.format(round(metrics.recall_score(y_test, y_pred) * 100, 2)))\n",
    "    \n",
    "    print('\\n'+model_name+' with using smote')\n",
    "    smote_m = model_classifier\n",
    "    \n",
    "    # SMOTE\n",
    "    pd_x_train, pd_x_test, pd_y_train, pd_y_test = train_test_split(X_train[features], y_train)\n",
    "    sm = SMOTE(random_state = 0)\n",
    "    X_sampled_smote, y_sampled_smote = sm.fit_resample(pd_x_train, pd_y_train)\n",
    "    \n",
    "    smote_m.fit(X_sampled_smote, y_sampled_smote)\n",
    "    y_pred_smote = smote_m.predict(X_test[features])\n",
    "    y_pred_proba_smote = smote_m.predict_proba(X_test[features])[:, 1]\n",
    "    confusion_matrix(y_test, y_pred_smote)\n",
    "    print('Validation test results:')\n",
    "    print('Test Score:', smote_m.score(pd_x_test, pd_y_test))\n",
    "    print('Accuracy Score:', metrics.accuracy_score(smote_m.predict(pd_x_test), pd_y_test))\n",
    "    print('Recall Score:', metrics.recall_score(pd_y_test, smote_m.predict(pd_x_test)))\n",
    "    \n",
    "    print('\\nTest Results:')\n",
    "    print('Test Score:', smote_m.score(X_test[features], y_test))\n",
    "    print('Accuracy Score:', metrics.accuracy_score(y_pred_smote, y_test))\n",
    "    print('Recall Score:', metrics.recall_score(y_test, y_pred_smote))\n",
    "    \n",
    "    return y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a5210-34b0-4833-9a1f-7dc9f597a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC(Y_test, Y_pred, Y_pred_prob, name):\n",
    "    precision = metrics.precision_score(Y_test, Y_pred)\n",
    "    recall = metrics.recall_score(Y_test, Y_pred)\n",
    "    fprcat, tprcat, thresholds = metrics.roc_curve(Y_test, Y_pred_prob)\n",
    "    AUC = metrics.auc(fprcat, tprcat)\n",
    "    plt.figure(figsize=(5,4), dpi=256)\n",
    "    plt.plot(fprcat, tprcat, 'b', label='AUC = %0.2f' % AUC)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    # plt.savefig(name + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5108e-c52e-419d-b9c1-3842f662b867",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5f942-1375-409b-9554-f3344a6369dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr_name = 'Logistic Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 1: without standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(no_stand_X_features, lr, lr_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'LR_nosd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'LR_nosd_nosm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efadf82-0ff9-453f-a86b-42d2b9b6e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2: with standardization\n",
    "y_pred_lr, y_pred_proba_lr, y_pred_smote, y_pred_proba_smote = model(stand_X_features, lr, lr_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'LR_sd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'LR_sd_nosm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ed913-013e-4df8-a67d-d0c8d2cd5784",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_name = 'Random Forest'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 1: without standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(no_stand_X_features, rf, rf_name)\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'RF_nosd_nosm')\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'RF_nosd_sm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 2: with standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(stand_X_features, rf, rf_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'RF_sd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'RF_sd_nosm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_name = 'KNeighborsClassifier'\n",
    "knn = KNeighborsClassifier(n_neighbors=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 1: without standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(no_stand_X_features, knn, knn_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'knn_nosd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'knn_nosd_nosm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 2: with standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(stand_X_features, knn, knn_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'knn_sd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'knn_sd_nosm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GBDT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gbdt = GradientBoostingClassifier()\n",
    "gbdt_name = 'Gradient Boosting Classifier'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 1: without standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(no_stand_X_features, gbdt, gbdt_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'GBDT_nosd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'GBDT_nosd_nosm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Case 2: with standardization\n",
    "y_pred, y_pred_proba, y_pred_smote, y_pred_proba_smote = model(stand_X_features, gbdt, gbdt_name)\n",
    "ROC(np.array(y_test), y_pred_smote, y_pred_proba_smote, 'GBDT_sd_sm')\n",
    "ROC(np.array(y_test), y_pred, y_pred_proba, 'GBDT_sd_nosm')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
